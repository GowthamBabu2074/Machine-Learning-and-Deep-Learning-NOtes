{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OptimizeCNNModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCZCuQgEv9rL"
      },
      "source": [
        "## Create CNN Model and Optimize it using Keras Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl4FyIx5v7qe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f68ly8opDabV"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYsZQvbtDaX3",
        "outputId": "b38184f5-db9d-4b5b-b5f9-b46bb4acec1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqR_yhxfDaWe",
        "outputId": "d8fd749e-c677-4b76-817c-902e42984d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Each image is a 32 x 32 x 3 numpy array\n",
        "x_train[444].shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFVOcjn5DaUT",
        "outputId": "6faec143-08b4-4a40-b9c7-7d0acf802b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "print(y_train[444])\n",
        "plt.imshow(x_train[444]);"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MCVtZbeDaSt"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8l0bUhrDaQR",
        "outputId": "845eb9a3-868b-484a-9480-8ba581e895cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\n",
        "y_train[444]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGyUJSaFDaOx"
      },
      "source": [
        "# As before, let's make everything float and scale\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0-9ycLzDaM-",
        "outputId": "e55512ae-df92-43a7-b476-9b2563b51f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 32)        2432      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 32)          25632     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               147968    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 181,162\n",
            "Trainable params: 181,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlDrUcqYDaLI",
        "outputId": "fe306c6c-da9c-4edf-ca91-27d7ae6bec6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 11s 6ms/step - loss: 1.9325 - accuracy: 0.2893 - val_loss: 1.4995 - val_accuracy: 0.4559\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4888 - accuracy: 0.4619 - val_loss: 1.3428 - val_accuracy: 0.5209\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3702 - accuracy: 0.5081 - val_loss: 1.2732 - val_accuracy: 0.5365\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3056 - accuracy: 0.5348 - val_loss: 1.2803 - val_accuracy: 0.5516\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2455 - accuracy: 0.5593 - val_loss: 1.1799 - val_accuracy: 0.5821\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2232 - accuracy: 0.5699 - val_loss: 1.1712 - val_accuracy: 0.5879\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1895 - accuracy: 0.5797 - val_loss: 1.1322 - val_accuracy: 0.5993\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1679 - accuracy: 0.5860 - val_loss: 1.0888 - val_accuracy: 0.6186\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1514 - accuracy: 0.5970 - val_loss: 1.1489 - val_accuracy: 0.5958\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1358 - accuracy: 0.5992 - val_loss: 1.1209 - val_accuracy: 0.6214\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1276 - accuracy: 0.6082 - val_loss: 1.0776 - val_accuracy: 0.6171\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1347 - accuracy: 0.6035 - val_loss: 1.1298 - val_accuracy: 0.6028\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1158 - accuracy: 0.6124 - val_loss: 1.1042 - val_accuracy: 0.6172\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1107 - accuracy: 0.6191 - val_loss: 1.0869 - val_accuracy: 0.6241\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1046 - accuracy: 0.6175 - val_loss: 1.0777 - val_accuracy: 0.6299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e5b684390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4979KhuGDaIR",
        "outputId": "90874a6b-dbf8-42c0-9437-64a7f59d4c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "\n",
        "model_2 = Sequential()\n",
        "\n",
        "model_2.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Conv2D(32, (3, 3)))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Conv2D(64, (3, 3)))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(512))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(num_classes))\n",
        "model_2.add(Activation('softmax'))\n",
        "## Check number of parameters\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiPyYsOJDaGF"
      },
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt_2 = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt_2,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxSx80-6EgpY"
      },
      "source": [
        "## Keras Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyA88xu8FLBD"
      },
      "source": [
        "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5hl35CJEnWN"
      },
      "source": [
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaTJWh1EzI_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963f0488-6e2a-4de2-f9a2-6c4ad693d5b1"
      },
      "source": [
        "train_images[0].shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLNQjFhgzM3U"
      },
      "source": [
        "train_images=train_images.reshape(len(train_images),28,28,1)\n",
        "test_images=test_images.reshape(len(test_images),28,28,1)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alNFfaFfzi6z"
      },
      "source": [
        "def build_model(hp):  \n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
        "        activation='relu',\n",
        "        input_shape=(28,28,1)\n",
        "    ),\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MISah2nO0sJg"
      },
      "source": [
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKFxb_pI05W-"
      },
      "source": [
        "tuner_search=RandomSearch(build_model,\n",
        "                          objective='val_accuracy',\n",
        "                          max_trials=5,directory='output',project_name=\"Fashion\")"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJRrQVI1jra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac60cdd-0681-4cbb-f582-2881975a1d6d"
      },
      "source": [
        "tuner_search.search(train_images,train_labels,epochs=3,validation_split=0.1)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 42s]\n",
            "val_accuracy: 0.9113333225250244\n",
            "\n",
            "Best val_accuracy So Far: 0.9136666655540466\n",
            "Total elapsed time: 00h 03m 44s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9in6O7E2Abd"
      },
      "source": [
        "model=tuner_search.get_best_models(num_models=1)[0]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qe6YrQV3g-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcb11db-bde3-4903-ae85-d30341ede66a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 112)       1120      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        32288     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1179712   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,213,770\n",
            "Trainable params: 1,213,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZKKr1IG3l6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ffc941-5983-400b-f30a-4facf1644f06"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10, validation_split=0.1, initial_epoch=3)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 15s 9ms/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.2559 - val_accuracy: 0.9142\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 14s 9ms/step - loss: 0.0979 - accuracy: 0.9637 - val_loss: 0.2868 - val_accuracy: 0.9157\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0690 - accuracy: 0.9743 - val_loss: 0.3124 - val_accuracy: 0.9150\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 14s 9ms/step - loss: 0.0455 - accuracy: 0.9840 - val_loss: 0.3676 - val_accuracy: 0.9135\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.4248 - val_accuracy: 0.9103\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 14s 9ms/step - loss: 0.0278 - accuracy: 0.9897 - val_loss: 0.5358 - val_accuracy: 0.9075\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 14s 9ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.5442 - val_accuracy: 0.9080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e5b371dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQz-cSf63zHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fd82a5-ed5b-47dd-d200-2cb09ff96b1a"
      },
      "source": [
        "eval_result = model.evaluate(test_images, test_labels)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5437 - accuracy: 0.9098\n",
            "[test loss, test accuracy]: [0.543693482875824, 0.9097999930381775]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOHQqkpNUAn4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}